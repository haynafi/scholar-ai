# --- Environment ---
# "development" = debug mode, docs enabled, reload on
# "production" = docs hidden, security headers, bind 0.0.0.0
APP_ENV=development
PORT=9999

# Optional: API secret key (protects sensitive endpoints in future)
API_SECRET_KEY=

# Optional: Your email for OpenAlex polite pool (faster rate limits)
OPENALEX_EMAIL=your-email@example.com

# --- LLM Provider (for AI summaries) ---
# "auto" = try Ollama first (free), fall back to OpenAI
# "ollama" = force Ollama only
# "openai" = force OpenAI only
LLM_PROVIDER=auto

# Ollama (FREE, local) â€” install from https://ollama.com
# Then run: ollama pull llama3.2
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# OpenAI (optional paid fallback)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Scopus API (free key from https://dev.elsevier.com)
# Enables "Scopus Indexed" badge and direct Scopus links
SCOPUS_API_KEY=

# CORS: Comma-separated allowed origins
# Development: *
# Production: https://scholar-ai.jagodev.com,https://www.jagodev.com
CORS_ORIGINS=*

# Rate limits (per IP per minute)
RATE_LIMIT_SEARCH=30/minute
RATE_LIMIT_SUMMARIZE=10/minute
RATE_LIMIT_EXPORT=5/minute
RATE_LIMIT_SCOPUS=20/minute
